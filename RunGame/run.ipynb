{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Inputs: [<KerasTensor: shape=(None, 84, 84, 1) dtype=float32 (created by layer 'input_2')>, <KerasTensor: shape=(None, 84, 84, 1) dtype=float32 (created by layer 'input_1')>]\n",
      "Model Input Shapes: [TensorShape([None, 84, 84, 1]), TensorShape([None, 84, 84, 1])]\n",
      "Model Outputs: [<KerasTensor: shape=(None, 18) dtype=float32 (created by layer 'prob')>]\n",
      "Model Output Shapes: [TensorShape([None, 18])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to initialize SDL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Shapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [output\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39moutputs])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Initialize the Ms. Pacman environment with render_mode='human'\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALE/Breakout-v5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_observation\u001b[39m(observation):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:640\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     render_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 640\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43menv_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m apply_human_rendering\n\u001b[1;32m    645\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ale_py/env/gym.py:155\u001b[0m, in \u001b[0;36mAtariEnv.__init__\u001b[0;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, max_num_frames_per_episode, render_mode)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39msetBool(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msound\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Seed + Load\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_set \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgetLegalActionSet()\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_action_space\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgetMinimalActionSet()\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_space \u001b[38;5;241m=\u001b[39m spaces\u001b[38;5;241m.\u001b[39mDiscrete(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_set))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ale_py/env/gym.py:215\u001b[0m, in \u001b[0;36mAtariEnv.seed\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(roms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_game):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWe\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre Unable to find the game \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_game\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Note: Gym no longer distributes ROMs. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you own a license to use the necessary ROMs for research purposes you can download them \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     )\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadROM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_game\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_game_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39msetMode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_game_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to initialize SDL"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define your custom softmax and KLD functions\n",
    "def my_softmax(x):\n",
    "    return tf.keras.activations.softmax(x, axis=-1)\n",
    "\n",
    "def my_kld(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    y_true = tf.clip_by_value(y_true, epsilon, 1)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1)\n",
    "    return tf.reduce_sum(y_true * tf.math.log(y_true / y_pred), axis=[1, 2, 3])\n",
    "\n",
    "# Load the trained AGIL model\n",
    "model_path = r\"./model.hdf5\"\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'my_softmax': my_softmax, 'my_kld': my_kld})\n",
    "\n",
    "# Inspect model input and output specifications\n",
    "print(\"Model Inputs:\", model.inputs)\n",
    "print(\"Model Input Shapes:\", [input.shape for input in model.inputs])\n",
    "print(\"Model Outputs:\", model.outputs)\n",
    "print(\"Model Output Shapes:\", [output.shape for output in model.outputs])\n",
    "\n",
    "# Initialize the Ms. Pacman environment with render_mode='human'\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode='human')\n",
    "obs = env.reset()\n",
    "\n",
    "def preprocess_observation(observation):\n",
    "    if isinstance(observation, tuple):\n",
    "        observation = np.array(observation[0])\n",
    "    else:\n",
    "        observation = np.array(observation)\n",
    "    \n",
    "    if len(observation.shape) == 3:\n",
    "        observation = tf.image.rgb_to_grayscale(observation)\n",
    "        observation = tf.image.resize(observation, [84, 84])\n",
    "        observation = tf.cast(observation, tf.float32) / 255.0\n",
    "        observation = tf.expand_dims(observation, axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Observation has an unexpected shape.\")\n",
    "    \n",
    "    return observation\n",
    "\n",
    "def select_action(model, observation):\n",
    "    processed_obs = preprocess_observation(observation)\n",
    "    \n",
    "    # Create placeholders for the second input if needed\n",
    "    additional_input = np.zeros((1, 84, 84, 1))  # Example shape, adjust as necessary\n",
    "    \n",
    "    # Combine the inputs into a list\n",
    "    inputs = [processed_obs, additional_input]\n",
    "\n",
    "    # Predict and suppress the progress bar\n",
    "    outputs = model.predict(inputs, verbose=0)\n",
    "    \n",
    "    # Extract action probabilities (assuming it's the second output)\n",
    "    action_probs = outputs[1]  # Adjust index based on your model's output order\n",
    "    \n",
    "    # print(\"Action Probabilities Shape:\", action_probs.shape)\n",
    "    \n",
    "    # Assuming action_probs should be a 2D array [batch_size, num_actions]\n",
    "    if action_probs.ndim == 2:\n",
    "        action = np.argmax(action_probs[0])  # Take the first batch element\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected shape for action probabilities.\")\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "for episode in range(10):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = select_action(model, obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
